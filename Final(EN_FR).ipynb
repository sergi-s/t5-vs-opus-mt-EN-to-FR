{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V54QpR935HDN",
        "outputId": "db9d9ca4-84e7-48cb-9e75-a44c42796151"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import MarianMTModel, MarianTokenizer, T5ForConditionalGeneration, T5Tokenizer\n",
        "from datasets import load_dataset\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "pJlQHTMZ5Jkw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmyy7unb9K6J",
        "outputId": "113be84c-0911-4ead-ab22-b98983de62d7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "model_save_path = '/content/drive/My Drive/MUN/Courses/ENGI-9867/Helsinki-NLP_trained_model.pt'\n",
        "helsinki_model = MarianMTModel.from_pretrained('Helsinki-NLP/opus-mt-en-fr')\n",
        "helsinki_model.load_state_dict(torch.load(model_save_path))\n",
        "tokenizer1 = MarianTokenizer.from_pretrained('Helsinki-NLP/opus-mt-en-fr')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "909pEbwm5P93",
        "outputId": "c42acf9e-9a67-493d-ea4c-be444987b079"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_path = '/content/drive/My Drive/MUN/Courses/ENGI-9867/t5_small_trained_model.pt'\n",
        "t5_model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
        "tokenizer2 = T5Tokenizer.from_pretrained('t5-small')\n",
        "\n",
        "# Load the saved state dictionary into the model\n",
        "t5_model.load_state_dict(torch.load(model_save_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmLqt9S4-RNg",
        "outputId": "5fd806cf-73ee-47ec-876c-b524c475ce2d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_with_models(text, model1, tokenizer1, model2, tokenizer2):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    def translate(text, model, tokenizer):\n",
        "        # Move model to the appropriate device\n",
        "        model.to(device)\n",
        "\n",
        "        if model.config.name_or_path.startswith('Helsinki-NLP'):\n",
        "            inputs = tokenizer(text, return_tensors='pt', padding=True)\n",
        "        else:\n",
        "            inputs = tokenizer('translate English to French: ' + text, return_tensors='pt', padding=True)\n",
        "\n",
        "        # Move inputs to the appropriate device\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(**inputs, max_new_tokens=50)\n",
        "\n",
        "        translated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        return translated_text\n",
        "\n",
        "    translated_text1 = translate(text, model1, tokenizer1)\n",
        "    translated_text2 = translate(text, model2, tokenizer2)\n",
        "\n",
        "    return translated_text1, translated_text2\n"
      ],
      "metadata": {
        "id": "DHLnsmFY5bJI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transate_comparison(text):\n",
        "  translation1, translation2 = translate_with_models(text, helsinki_model, tokenizer1, t5_model, tokenizer2)\n",
        "  print(\"helsinki translation:\\t\", translation1)\n",
        "  print(\"T5 translation:\\t\\t\", translation2)\n"
      ],
      "metadata": {
        "id": "ehTKike--Tl1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transate_comparison(\"Hello, how are you?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48wM8kCS_jpu",
        "outputId": "5f99256f-1730-4c7e-a0d8-e265702390c8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "helsinki translation:\t Bonjour, comment allez-vous?\n",
            "T5 translation:\t\t Bonjour, comment êtes-vous?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transate_comparison(\"I want to eat a hamburger\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdGC3g6R-z0E",
        "outputId": "55964a3c-fe5b-43c2-fc1c-785d13367016"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "helsinki translation:\t Je veux manger un hamburger.\n",
            "T5 translation:\t\t Je veux manger un hamburger\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transate_comparison(\"I am happy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsMA0np7_KJE",
        "outputId": "12529c7f-0d5e-4aa5-854a-c3cbcae4dc73"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "helsinki translation:\t Je suis heureux.\n",
            "T5 translation:\t\t Je suis heureuse\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transate_comparison(\"I am sad\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyNKCp0v_X4g",
        "outputId": "1873ba93-f127-407f-e525-9bf65d8f986a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "helsinki translation:\t Je suis triste.\n",
            "T5 translation:\t\t Je suis triste\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transate_comparison(\"There should be difference between these two translations\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqCc0huT_ZKC",
        "outputId": "230a87e0-41a1-458c-a913-7676bb427e8b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "helsinki translation:\t Il devrait y avoir une différence entre ces deux traductions\n",
            "T5 translation:\t\t Il faudrait y avoir une différence entre ces deux traductions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eHO0BiOP_22C"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}